#!/usr/bin/env python

import optparse, os
import numpy as np
import statistics as stat
import itertools as it
import math
from collections import defaultdict



# This script reads in 1) normalized or raw read counts and 2) bins and calculated zscores

def main():
    usage = '%prog [options]'
    p = optparse.OptionParser()
    p.add_option('-s', '--scores',  help='Score file to use for calculating Z scores. [None, REQ]')
    p.add_option('-b', '--bins',  help='Bin file, in the format generated by the PepSIRF bin module. [None, REQ]')
    p.add_option('--hpd', type="float", help="Highest posterior density to use for calculation of mean and standard deviation. Must be between 0 and 1. [None, REQ]")
    p.add_option('-o', '--outfile', help='Name for output Z score matrix file [None, REQ]')
    opts, args = p.parse_args()
    
    # Read in bins
    bins = readGroups(opts.bins)
    
    # Read in matrices
    sD = parseCounts(opts.scores)

    # Calculate Z scores
    zD = zScores(sD, bins, opts.hpd)

    #Write output Z score file
    writeCounts(zD, opts.outfile)

#----------------------End of main()


def readGroups(file):
    g=[]
    with open(file, "r") as fin:
        for line in fin:
            cols=line.rstrip("\n").split("\t")
            if cols:
                g.append(cols)
    return g

def zScores (cDfull, grps, hpd):
    return {k:indivZ(v,grps,hpd, k) for k,v in cDfull.items()}

def indivZ(cD, grps, hpd, temp):
    zD={}
    for i, g in enumerate(grps):
        counts=[cD[each] for each in g]
        lo,hi=get_hpd(counts,hpd)

        mid = [x for x in counts if x>=lo and x<=hi]
        
        avg = np.mean(mid)
        std = stat.stdev(mid)
        
        print(temp, i, avg, std, len(g), len(mid))
        
        for p in g:
            zD[p]=(cD[p]-avg)/std
    return zD

def writeCounts(cd, outname):
    probeNames = sorted(cd[list(cd.keys())[0]].keys())
    sampNames =  sorted(list(cd.keys()))
    with open(outname, "w") as fout:
        fout.write("Probe\t%s\n" % ("\t".join(sampNames)))
        for each in probeNames:
            fout.write("%s\t%s\n" % (each, "\t".join([str(cd[x][each]) for x in sampNames])))


def parseCounts(countFile, delim="\t"):
    counts={}
    with open(countFile, "r") as fin:
        lc=0
        for line in fin:
            lc+=1
            cols=line.rstrip("\n").split(delim)
            if lc == 1:
                names = cols[1:]
                for n in names:
                    counts[n]={}
            else:
                for i, count in enumerate(cols[1:]):
                    counts[names[i]][cols[0]] = float(count)
    return counts


def get_hpd(data, level):
    """
    Return highest posterior density interval from a list,
    given the percent posterior density interval required.
    """
    d = list(data)
    d.sort()

    nData = len(data)
    nIn = int(round(level * nData))
    if nIn < 2 :
        return None
   #raise RuntimeError("Not enough data. N data: %s"%(len(data)))
 
    i = 0
    r = d[i+nIn-1] - d[i]
    for k in range(len(d) - (nIn - 1)) :
        rk = d[k+nIn-1] - d[k]
        if rk < r :
            r = rk
            i = k

    assert 0 <= i <= i+nIn-1 < len(d)
 
    return (d[i], d[i+nIn-1])


###------------------------------------->>>>    

if __name__ == "__main__":
    main()

