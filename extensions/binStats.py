#!/usr/bin/env python

import optparse
import numpy as np
import statistics as stat


def main():
    usage = '%prog [options]'
    p = optparse.OptionParser()
    p.add_option('-i', '--input',  help='Tab-delimited input file, with one row per input matrix. The first column should contain a simple string to be used in output to refer to this file. The second column should be a score matrix that would be used to calculate Z scores [None, REQ]')
    p.add_option('-b', '--bins',  help='Bin file, in the format generated by the PepSIRF bin module. [None, REQ]')
    p.add_option('--hpd', type="float", help="Highest posterior density to use for calculation of mean and standard deviation. Must be between 0 and 1. [None, REQ]")
    p.add_option('-o', '--out', help='Name for output tab-delimited file with info about the mean and standard deviation for each sample and each bin. [None, REQ]')
    opts, args = p.parse_args()
    
    # Read in bins
    bins = readGroups(opts.bins)
    
    # Open output file for writing
    with open(opts.out, "w") as fout:
        #Write header for output file
        fout.write("Sample\tFile\tBin\tMeanHDI%d\tStdevHDI%d\n" % (int(opts.hpd*100), int(opts.hpd*100)))
        
        #Step through each score matrix file
        with open(opts.input, "r") as fin:
            for line in fin:
                fileStr,fileLoc = line.rstrip("\n").split("\t")
                
                # Read in matrix
                sD = parseCounts(fileLoc)

                for samp, cD in sD.items():
                    for i, g in enumerate(bins):
                        counts=[cD[each] for each in g]
                        lo,hi=get_hpd(counts,opts.hpd)

                        mid = [x for x in counts if x>=lo and x<=hi]
        
                        avg = np.mean(mid)
                        std = stat.stdev(mid)
                        
                        fout.write("%s\t%s\t%d\t%.5f\t%.5f\n" % (samp, fileStr, i, avg, std))

#----------------------End of main()


def readGroups(file):
    g=[]
    with open(file, "r") as fin:
        for line in fin:
            cols=line.rstrip("\n").split("\t")
            if cols:
                g.append(cols)
    return g


def writeCounts(cd, outname):
    probeNames = sorted(cd[list(cd.keys())[0]].keys())
    sampNames =  sorted(list(cd.keys()))
    with open(outname, "w") as fout:
        fout.write("Probe\t%s\n" % ("\t".join(sampNames)))
        for each in probeNames:
            fout.write("%s\t%s\n" % (each, "\t".join([str(cd[x][each]) for x in sampNames])))


def parseCounts(countFile, delim="\t"):
    counts={}
    with open(countFile, "r") as fin:
        lc=0
        for line in fin:
            lc+=1
            cols=line.rstrip("\n").split(delim)
            if lc == 1:
                names = cols[1:]
                for n in names:
                    counts[n]={}
            else:
                for i, count in enumerate(cols[1:]):
                    counts[names[i]][cols[0]] = float(count)
    return counts


def get_hpd(data, level):
    """
    Return highest posterior density interval from a list,
    given the percent posterior density interval required.
    """
    d = list(data)
    d.sort()

    nData = len(data)
    nIn = int(round(level * nData))
    if nIn < 2 :
        return None
   #raise RuntimeError("Not enough data. N data: %s"%(len(data)))
 
    i = 0
    r = d[i+nIn-1] - d[i]
    for k in range(len(d) - (nIn - 1)) :
        rk = d[k+nIn-1] - d[k]
        if rk < r :
            r = rk
            i = k

    assert 0 <= i <= i+nIn-1 < len(d)
 
    return (d[i], d[i+nIn-1])


###------------------------------------->>>>    

if __name__ == "__main__":
    main()

